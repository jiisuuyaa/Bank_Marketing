import streamlit as st
import pandas as pd
import numpy as np
import optuna
import matplotlib.pyplot as plt
from PIL import Image
import requests
from io import BytesIO
import sqlite3

from sqlalchemy import create_engine

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, make_scorer
from sklearn.preprocessing import LabelEncoder

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

import optuna.visualization.matplotlib as optuna_viz


# ì‚¬ì´ë“œë°”ì— ë©”ë‰´ ì¶”ê°€
menu = st.sidebar.radio("ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”", ['Optuna ëŒ€ì‹œë³´ë“œ', 'í”¼ì²˜ ì„ íƒ ë° GBM ì„±ëŠ¥'])

# Optuna ëŒ€ì‹œë³´ë“œ ì„ íƒ ì‹œ ë³´ì—¬ì¤„ ë‚´ìš©
if menu == 'Optuna ëŒ€ì‹œë³´ë“œ':
    # ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì œëª©ê³¼ ì„¤ëª… ê¾¸ë¯¸ê¸°
    st.markdown("# ğŸˆOptuna ëŒ€ì‹œë³´ë“œğŸˆ")
    st.markdown("## ğŸ”ê°€ì¥ ì¢‹ì€ ëª¨ë¸ì€ ë¬´ì—‡ì¼ê¹Œë‚­")
    st.markdown("### Optunaë¥¼ í™œìš©í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê²°ê³¼ë¥¼ ì‹œê°í™”ğŸ“Œ")
    st.markdown("---")  # êµ¬ë¶„ì„ 

    # 4ê°œì˜ ì—´ì„ ìƒì„±í•˜ì—¬ ì´ë¯¸ì§€ ë°°ì¹˜
    col1, col2, col3, col4 = st.columns(4)

    # ì´ë¯¸ì§€ URLì„ í†µí•´ ë¶ˆëŸ¬ì˜¤ê¸°
    image1_url = "https://github.com/user-attachments/assets/fe421d0c-b67b-41fe-af8c-5e650e75e5d4"
    image2_url = "https://github.com/user-attachments/assets/9914a37f-9548-4e99-b1ea-0a58efce773b"
    image3_url = "https://github.com/user-attachments/assets/4b52fa99-524e-432f-816d-09de85938f04"
    image4_url = "https://github.com/user-attachments/assets/ec09a2ef-252d-446b-9bf4-849d1ad13e2c"

    # ì´ë¯¸ì§€ ë™ì¼í•œ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
    def resize_image(image_url, size=(150, 150)):
        response = requests.get(image_url)  # URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        img = Image.open(BytesIO(response.content))  # BytesIOë¥¼ ì‚¬ìš©í•´ Pillowë¡œ ì—´ê¸°
        img = img.resize(size)
        return img

    # ê° ì—´ì— ì´ë¯¸ì§€ë¥¼ ë„£ê¸°
    with col1:
        st.image(resize_image(image1_url), caption='ğŸ€í•˜ì˜í•‘')

    with col2:
        st.image(resize_image(image2_url), caption='ğŸ‘°ğŸ»í¬ì„±í•‘')

    with col3:
        st.image(resize_image(image3_url), caption='ğŸ¤ìƒë¯¼í•‘')

    with col4:
        st.image(resize_image(image4_url), caption='ğŸ°ì§€ìˆ˜í•‘')

    # Optuna study ë¡œë“œ
    db_path = 'bank_marketing_optuna.db'
    engine = create_engine(f'sqlite:///{db_path}')



    try:
        study = optuna.load_study(study_name='bank_marketing_optimization', storage=f'sqlite:///{db_path}')
    except KeyError:
        st.error("í•´ë‹¹ ì´ë¦„ì˜ Studyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        study = None

    if study:
        # ì„±ê³¼ ê¸°ë¡ ì‹œê°í™” (Optimization History)
        st.markdown("## ìµœì í™” ê¸°ë¡")
        st.markdown("ì•„ë˜ ê·¸ë˜í”„ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ê³¼ì •ì—ì„œ ì„±ëŠ¥ì´ ì–´ë–»ê²Œ ë³€í–ˆëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
        ax = optuna_viz.plot_optimization_history(study)
        fig = ax.get_figure()
        st.pyplot(fig)

        # ë³‘ë ¬ ì¢Œí‘œ í”Œë¡¯ (Parallel Coordinate Plot)
        st.markdown("## ë³‘ë ¬ ì¢Œí‘œ ê·¸ë˜í”„")
        st.markdown("ì—¬ëŸ¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì´ ëª¨ë¸ ì„±ëŠ¥ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì³¤ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        ax2 = optuna_viz.plot_parallel_coordinate(study)
        fig2 = ax2.get_figure()
        st.pyplot(fig2)

        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¤‘ìš”ë„ (Hyperparameter Importance)
        st.markdown("## í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¤‘ìš”ë„")
        st.markdown("ê° í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°€ ëª¨ë¸ ì„±ëŠ¥ì— ì–¼ë§ˆë‚˜ ê¸°ì—¬í–ˆëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
        ax3 = optuna_viz.plot_param_importances(study)
        fig3 = ax3.get_figure()
        st.pyplot(fig3)

        from sqlalchemy import text

        # ì‹œê°í™”ë˜ì§€ ì•Šì€ study ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í™•ì¸
        st.markdown("## ìµœì í™” ì‹¤í—˜ ë°ì´í„°")
        with engine.connect() as connection:
            result = connection.execute(text('SELECT * FROM studies'))
            df = pd.DataFrame(result.fetchall(), columns=result.keys())
        st.write(df)

        # Trials ë°ì´í„°
        st.markdown("## íŠ¸ë¼ì´ì–¼ ë°ì´í„°")
        with engine.connect() as connection:
            result = connection.execute(text('SELECT * FROM trials'))
            df_trials = pd.DataFrame(result.fetchall(), columns=result.keys())
        st.write(df_trials)

        

    # ì¶”ê°€ì ì¸ ì •ë³´
    st.markdown("---")  # êµ¬ë¶„ì„ 
    st.markdown("### ì œì‘ì: í•˜ì˜ìƒë¯¼ì§€ìˆ˜í¬ì„±í•‘")
    st.markdown("[ğŸ”— GitHub ë§í¬](https://github.com/sangminpark9/ML041)")










# ì»¤ìŠ¤í…€ ìŠ¤ì½”ì–´ í•¨ìˆ˜ (AUCì™€ Recallì˜ ì¡°í™” í‰ê· )
def custom_score(y_true, y_pred_proba):
    auc = roc_auc_score(y_true, y_pred_proba)
    recall = recall_score(y_true, y_pred_proba > 0.5, pos_label=1)
    return 2 * (auc * recall) / (auc + recall)

custom_scorer = make_scorer(custom_score, needs_proba=True)

st.markdown("# í”¼ì²˜ ì„ íƒ ë° Soft Voting ëª¨ë¸ ì„±ëŠ¥ ì‹œê°í™”")
st.write("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³ , ì‚¬ìš©í•  í”¼ì²˜ë¥¼ ì„ íƒí•˜ì—¬ Soft Voting ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í™•ì¸í•˜ì„¸ìš”.")

# CSV íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["csv"])

if uploaded_file is not None:
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(uploaded_file)

    # ë°ì´í„°í”„ë ˆì„ê³¼ íƒ€ê²Ÿ ì»¬ëŸ¼ ë¶„ë¦¬
    target_column = 'deposit'  # íƒ€ê²Ÿ ì»¬ëŸ¼ì´ 'deposit'ì´ë¼ê³  ê°€ì •
    features = df.drop(columns=[target_column, 'duration'])
    target = df[target_column]

    # íƒ€ê²Ÿ ë³€ìˆ˜ ë³€í™˜ ('no', 'yes' -> 0, 1)
    le = LabelEncoder()
    y = le.fit_transform(target)

    # ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ One-Hot Encodingìœ¼ë¡œ ë³€í™˜
    features_encoded = pd.get_dummies(features, drop_first=True)

    # í”¼ì²˜ ì„ íƒì„ ìœ„í•œ ë©€í‹°ì…€ë ‰íŠ¸
    selected_features = st.multiselect('ì‚¬ìš©í•  í”¼ì²˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:', features_encoded.columns.tolist(), default=features_encoded.columns.tolist())

    # ë°ì´í„°ê°€ ì„ íƒë˜ì—ˆì„ ê²½ìš°
    if selected_features:
        X = features_encoded[selected_features]

        # Train-Test Split
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # ëª¨ë¸ ì •ì˜
        rf = RandomForestClassifier(random_state=42)
        xgb = XGBClassifier(random_state=42)
        lgbm = LGBMClassifier(random_state=42)

        # Voting Classifier ìƒì„±
        voting_clf = VotingClassifier([
            ('rf', rf),
            ('xgb', xgb),
            ('lgbm', lgbm)
        ], voting='soft', weights=[1, 1, 1])

        # ëª¨ë¸ í•™ìŠµ
        voting_clf.fit(X_train, y_train)

        # ì˜ˆì¸¡
        y_pred = voting_clf.predict(X_test)
        y_pred_proba = voting_clf.predict_proba(X_test)[:, 1]

        # ì„±ëŠ¥ í‰ê°€
        acc = accuracy_score(y_test, y_pred)
        auc = roc_auc_score(y_test, y_pred_proba)
        rec = recall_score(y_test, y_pred)

        # ì„±ëŠ¥ ê²°ê³¼ ì¶œë ¥
        st.write(f"**ì„ íƒëœ í”¼ì²˜ ìˆ˜**: {len(selected_features)}")
        st.write(f"**Accuracy**: {acc:.4f}")
        st.write(f"**AUC**: {auc:.4f}")
        st.write(f"**Recall**: {rec:.4f}")

        # ì¶”ê°€: ê° ëª¨ë¸ì˜ ê°œë³„ ì„±ëŠ¥ ë¹„êµ
        st.markdown("## ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
        for name, model in voting_clf.named_estimators_.items():
            y_pred_individual = model.predict(X_test)
            y_pred_proba_individual = model.predict_proba(X_test)[:, 1]
            
            acc_individual = accuracy_score(y_test, y_pred_individual)
            auc_individual = roc_auc_score(y_test, y_pred_proba_individual)
            rec_individual = recall_score(y_test, y_pred_individual)
            
            st.write(f"**{name} ëª¨ë¸**")
            st.write(f"Accuracy: {acc_individual:.4f}")
            st.write(f"AUC: {auc_individual:.4f}")
            st.write(f"Recall: {rec_individual:.4f}")
            st.write("---")
